<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">

    <title>Large Language Models for Agents</title>
    <meta content="Workshop on LLM Agents @ ICLR 2024" name="description">
    <meta content name="keywords">

    <!-- Favicons -->
    <link href="assets/img/favicon.png" rel="icon">
    <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

    <!-- Google Fonts -->
    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i, Raleway:300,300i,400,400i,500,500i,600,600i,700,700i, Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
      rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css"
      rel="stylesheet">
    <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

    <!-- Template Main CSS File -->
    <link href="assets/css/style.css" rel="stylesheet">

    <style>
    li {
      margin: 10px 10px 10px 10px;
    }
    </style>

    <style>
  .interactive-panel {
    padding: 10px;
    border: 1px solid #ddd;
    border-radius: 5px;
    transition: all 0.3s ease;
    margin-bottom: 15px; /* Add margin to the bottom of each panel */
  }

  .interactive-panel:hover {
    border-color: #007bff;
    box-shadow: 0 0 10px rgba(0, 123, 255, 0.5);
    cursor: pointer;
  }
</style>

    <style>
  /* CSS for coloring schedule rows */
  .morning-session {
    background-color: #fff4d5; /* Light yellow for morning sessions */
  }

  .afternoon-session {
    background-color: #dbe7f2; /* Light blue for afternoon sessions */
  }

  .evening-session {
    background-color: #e9daeb; /* Light purple for evening sessions */
  }

  .night-session {
    background-color: #f9f0ed; /* Light purple for evening sessions */
  }

</style>

  </head>

  <body>

    <!-- ======= Header ======= -->
    <header id="header"
      class="fixed-top d-flex align-items-center  header-transparent ">
      <div class="container d-flex align-items-center justify-content-between">

        <div class="logo">

          <!-- Uncomment below if you prefer to use an image logo -->
          <h1><a href="https://llmagents.github.io/" target="blank_"> </a></h1>

          <!-- <img src="assets/img/logo.png" alt="TamingLLM@SIGDIAL & INLG 2023"> -->

          <!-- <p style="margin : 0; padding-top:0; padding-left: 80px; padding-bottom:0;  line-height:0; font-size: 10px; text-align: center;" class="green-text">
        May 26-28, 2022 ,  Dublin
      </p> -->
        </div>

        <nav id="navbar" class="navbar">
          <ul>
            <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
            <!-- <li><a class="nav-link scrollto" href="#about">About</a></li> -->
            <li><a class="nav-link scrollto" href="#topics">Topics</a></li>
            <li><a class="nav-link scrollto" href="#cfp">Call for
                Papers</a></li>
            <li><a class="nav-link scrollto" href="#accepted-papers">Accepted
                Papers</a></li>
            <li><a class="nav-link scrollto" href="#speaker">Speakers</a></li>
            <li><a class="nav-link scrollto" href="#panelist">Panelists</a></li>

            <li><a class="nav-link scrollto" href="#schedule">Schedule</a></li>
            <li><a class="nav-link scrollto" href="#org">Organization</a></li>
            <li><a class="nav-link scrollto" href="#reviewers">Reviewers</a></li>
            <li><a class="nav-link scrollto" href="#contact">Contact</a></li>
          </ul>
          <i class="bi bi-list mobile-nav-toggle"></i>
        </nav><!-- .navbar -->

      </div>
    </header><!-- End Header -->

    <!-- ======= Hero Section ======= -->

    <section id="hero"
      class="d-flex flex-column justify-content-end align-items-center">
      <div id="heroCarousel" data-bs-interval="5000"
        class="container carousel carousel-fade" data-bs-ride="carousel">

        <!-- Slide 1 -->
        <div class="carousel-item active">
          <div class="carousel-container">
            <h2 class="animate__animated animate__fadeInDown"
              style="font-size: 60px;"> ICLR 2024 Workshop on LLM Agents
            </h2>

            <h2 class="animate__animated animate__fadeInDown"
              style="color: white;">May 11, 2024 in Vienna, Austria</h2>

            <p class="animate__animated animate__fadeInDown">
              Links:
              <a
                href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fctrlnlg.github.io%2F&ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5Ectrl_nlg&region=follow_link&screen_name=LLMAgents"
                target="_blank"
                style="color: lightgrey;">Twitter</a> |
              <a
                href="https://openreview.net/group?id=ICLR.cc/2024/Workshop/LLMAgents"
                target="_blank"
                style="color: lightgrey;">OpenReview</a> |
              <a href="https://iclr.cc/Conferences/2024/Dates" target="_blank"
                style="color: lightgrey;">ICLR 2024</a>
            </p>

            <p class="animate__animated fanimate__adeInUp">

            </p>
          </div>
        </div>

      </div>

      <svg class="hero-waves" xmlns="http://www.w3.org/2000/svg"
        xmlns:xlink="http://www.w3.org/1999/xlink"
        viewBox="0 24 150 28 " preserveAspectRatio="none">
        <defs>
          <path id="wave-path"
            d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z">
          </defs>
          <g class="wave1">
            <use xlink:href="#wave-path" x="50" y="3"
              fill="rgba(255,255,255, .1)">
            </g>
            <g class="wave2">
              <use xlink:href="#wave-path" x="50" y="0"
                fill="rgba(255,255,255, .2)">
              </g>
              <g class="wave3">
                <use xlink:href="#wave-path" x="50" y="9" fill="#fff">
                </g>
              </svg>

            </section><!-- End Hero -->

            <main id="main">

              <section id="about" class="contact">
                <div class="container">
                  <div class="row">
                    <div class="col-md-1">
                    </div>
                    <div class="col-md-6">

                      <p style="font-size: 20px;">
                        ICLR 2024 Workshop on LLM Agents delves into the
                        significance of agents
                        driven by large language models (LLMs), a topic that has
                        recently sparked intense discussions. Building on the
                        current huge progress on LLMs, we'll focus on autonomous
                        agents that perform intricate tasks in both real and
                        simulated environments guided by natural language
                        instructions. What sets these agents apart is their
                        sophisticated use of language prompts, not just as a
                        means of communication but also as a medium for
                        reasoning—a characteristic once thought unique to
                        humans.
                        <br>
                        <br>
                        Previous Workshop: <a
                          href="https://ctrlnlg.github.io/"
                          target="blank_">TamingLLM @ Sigdial & INLG 2023</a>
                      </p>
                    </div>
                    <div class="col-3">
                      <p> <img src="assets/img/taming3.jpg" class="img-fluid"
                          alt> <a></a> </p>
                    </div>
                    <div class="col-md-1">
                    </div>
                  </div>
                </div>

              </section><!-- End About Section -->

              <!-- ======= Topics Section ======= -->
              <section id="topics" class="team">
                <div class="container">
                  <div class="section-title" data-aos="zoom-out">
                    <h2>Topics</h2>
                  </div>
                  <div class="container">
                    <div class="row">
                      <p>We will explore a range of topics in this workshop,
                        including, but not limited to, the following areas:</p>
                    </div>

                    <!-- Panel for each topic -->
                    <div class="row">
                      <!-- Topic 1 -->
                      <div class="col-md-4">
                        <div class="topic-panel interactive-panel">
                          <b>Memory Mechanisms and Linguistic
                            Representation:</b>
                          <p>This session will analyze the similarities between
                            LLMs and human memory and will discuss the
                            mechanisms
                            of storage and formation of the linguistic
                            representation in LLMs.</p>
                        </div>
                      </div>

                      <!-- Topic 2 -->
                      <div class="col-md-4">
                        <div class="topic-panel interactive-panel">
                          <b>Tool Augmentation and Grounding (interaction with
                            environment):</b>
                          <p>Addressing the enhancement of LLMs through tool
                            augmentation, this session will also include a
                            discourse on grounding – linking natural language
                            concepts to particular contexts.</p>
                        </div>
                      </div>

                      <!-- Topic 3 -->
                      <div class="col-md-4">
                        <div class="topic-panel interactive-panel">
                          <b>Reasoning, Planning, and Risks:</b>
                          <p>This session will discuss the intertwined processes
                            of reasoning and planning in language agents and
                            highlight the potential hazards associated with
                            language agents' ability to autonomously operate in
                            the real world.</p>
                        </div>
                      </div>
                    </div>

                    <div class="row">
                      <!-- Topic 4 -->
                      <div class="col-md-6">
                        <div class="topic-panel interactive-panel">
                          <b>Multi-modality and Integration in Language
                            Agents:</b>
                          <p>This session will explore how language agents can
                            integrate multiple modalities such as vision, sound,
                            and touch to enhance their understanding and
                            interaction with the environment.</p>
                        </div>
                      </div>

                      <!-- Topic 5 -->
                      <div class="col-md-6">
                        <div class="topic-panel interactive-panel">
                          <b>Conceptual Framework for Language Agents:</b>
                          <p>This session will delve into a potential framework
                            for language agents by drawing from both classic and
                            contemporary AI research and related fields such as
                            neuroscience, cognitive science, and
                            linguistics.</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </section><!-- End Topics Section -->

              <!-- ======= Speaker Section ======= -->
              <section id="speaker" class="team">
                <div class="container">
                  <div class="section-title" data-aos="zoom-out">
                    <h2>Speakers</h2>
                  </div>

                  <div class="row">
                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/speaker/denny.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://dennyzhou.github.io/">Denny
                              Zhou</a></h4>
                          <strong>Principal Scientist/Research Director, Google
                            DeepMind</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/speaker/luke.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a
                              href="https://www.cs.washington.edu/people/faculty/lsz">Luke Zettlemoyer</a></h4>
                          <strong>Professor, Allen School of Computer Science & Engineering, University of Washington</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img
                            src="https://cdn.snorkel.ai/wp-content/uploads/2022/04/Chelsea-Finn_thumb.png"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://ai.stanford.edu/~cbfinn/">Chelsea
                              Finn</a></h4>
                          <strong>Assistant Professor, Stanford
                            University</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img
                            src="https://media.licdn.com/dms/image/C5103AQFTdhOlm8UynQ/profile-displayphoto-shrink_800_800/0/1516845291134?e=2147483647&v=beta&t=COHXwD0KW20To7Up-Zoc1_zwC6p-Z3mdecxz_-r5tyg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a
                              href="https://www.cs.princeton.edu/~karthikn/">Karthik
                              Narasimhan</a></h4>
                          <strong>Assistant Professor, Computer Science,
                            Princeton University</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img
                            src="https://www.nextcanada.com/wp-content/uploads/2019/09/graham-neubig.jpg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://www.phontron.com/">Graham
                              Neubig</a></h4>
                          <strong>Associate Professor, CMU LTI</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img
                            src="data:image/jpeg;base64,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"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a
                              href="https://web.eecs.umich.edu/~chaijy/">Joyce
                              Y. Chai</a></h4>
                          <strong>Professor, University of Michigan</strong>
                        </div>
                      </div>
                    </div>

                  </div>
                </section>

              <!-- ======= Panelist Section ======= -->
              <section id="panelist" class="team">
                <div class="container">
                  <div class="section-title" data-aos="zoom-out">
                    <h2>Panelist</h2>
                  </div>

                  <div class="row">
                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/panelist/tao.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://taoyds.github.io/">Tao Yu</a></h4>
                          <strong>Assistant Professor, The University of Hong Kong</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/panelist/roberta.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://rraileanu.github.io/">Roberta Raileanu</a></h4>
                          <strong>Research Scientist, Meta GenAI</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/panelist/alexandre.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://www.alexdrouin.com/">Alexandre Drouin</a></h4>
                          <strong>Staff Research Scientist, ServiceNow Research </strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/speaker/denny.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://dennyzhou.github.io/">Denny
                              Zhou</a></h4>
                          <strong>Principal Scientist/Research Director, Google
                            DeepMind</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img
                            src="https://www.nextcanada.com/wp-content/uploads/2019/09/graham-neubig.jpg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a href="https://www.phontron.com/">Graham
                              Neubig</a></h4>
                          <strong>Associate Professor, CMU LTI</strong>
                        </div>
                      </div>
                    </div>

                    <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                      <div class="member" data-aos="fade-up">
                        <div class="member-img">
                          <img src="assets/img/speaker/luke.jpeg"
                            class="img-fluid" alt>
                        </div>
                        <div class="member-info">
                          <h4><a
                              href="https://www.cs.washington.edu/people/faculty/lsz">Luke Zettlemoyer</a></h4>
                          <strong>Professor, Allen School of Computer Science & Engineering, University of Washington</strong>
                        </div>
                      </div>
                    </div>

                    

                  </div>
                </section>

                <!-- ======= Schedule Section ======= -->
                <!-- ======= Workshop Schedule Section ======= -->
                <section id="schedule" class="schedule">
                  <div class="container">
                    <div class="section-title" data-aos="zoom-out">
                      <h2>Workshop Schedule</h2>
                    </div>

                    <div class="row">
                      <div class="col-lg-12">
                        <div class="schedule-table">
                          <table class="table">
                            <thead>
                              <tr>
                                <th scope="col">Time</th>
                                <th scope="col">Session</th>
                                <th scope="col">Duration</th>
                                <th scope="col">Details</th>
                              </tr>
                            </thead>
                            <tbody>
                              <!-- Opening Remarks -->
                              <tr class="morning-session">
                                <td>8:40AM - 8:45AM</td>
                                <td>Opening Remarks</td>
                                <td>5 min</td>
                                <td>Welcome and Introduction to the Workshop</td>
                              </tr>
                              <!-- Invited Talk 1 -->
                              <tr class="morning-session">
                                <td>8:45AM - 9:15AM</td>
                                <td>Invited Talk #1</td>
                                <td>30 min</td>
                                <td>Denny Zhou: LLM Reasoning: Key Ideas and Limitations</td>
                              </tr>
                              <!-- Spotlight Presentation 1 -->
                              <tr class="morning-session">
                                <td>9:15AM - 9:25AM</td>
                                <td>Spotlight Presentation #1</td>
                                <td>10 mins</td>
                                <td>AutoGen</td>
                              </tr>
                              <tr class="morning-session">
                                <td>9:25AM - 9:35AM</td>
                                <td>Spotlight Presentation #2</td>
                                <td>10 mins</td>
                                <td>Data-Copilot</td>
                              </tr>
                              <!-- Invited Talk 2 -->
                              <tr class="morning-session">
                                <td>9:35AM - 10:05AM</td>
                                <td>Invited Talk #2</td>
                                <td>30 min</td>
                                <td>Luke Zettlemoyer: ART: Automatic multi-step reasoning and tool-use for large language models</td>
                              </tr>
                              <!-- Coffee Break -->
                              <tr>
                                <td>10:05AM - 10:30AM</td>
                                <td>Coffee Break</td>
                                <td>25 min</td>
                                <td>Networking and refreshments</td>
                              </tr>
                              <!-- Spotlight Presentation 3 -->
                              <tr class="afternoon-session">
                                <td>10:30AM - 10:40AM</td>
                                <td>Spotlight Presentation #3</td>
                                <td>10 mins</td>
                                <td>AutoAct</td>
                              </tr>
                              <!-- Spotlight Presentation 4 -->
                              <tr class="afternoon-session">
                                <td>10:40AM - 10:50AM</td>
                                <td>Spotlight Presentation #4</td>
                                <td>10 mins</td>
                                <td>Large Language Models can Strategically Deceive their Users</td>
                              </tr>
                              <!-- Invited Talk #3 -->
                              <tr class="afternoon-session">
                                <td>10:50AM - 11:20AM</td>
                                <td>Invited Talk #3</td>
                                <td>30 min</td>
                                <td>Graham Neubig: OpenDevin: A Platform for AI Agents Supporting Software Development, Web Navigation, and Beyond</td>
                              </tr>
                              <!-- Poster Session 1 -->
                              <tr class="afternoon-session">
                                <td>11:20AM - 12:15PM</td>
                                <td>Poster Session I</td>
                                <td>55 min</td>
                                <td>First session for display and discussion of all accepted submissions</td>
                              </tr>
                              <!-- Lunch Break -->
                              <tr>
                                <td>12:15PM - 1:15PM</td>
                                <td>Lunch Break</td>
                                <td>60 min</td>
                                <td>Time for lunch and informal discussions</td>
                              </tr>
                              <!-- Panel Discussion -->
                              <tr class="evening-session">
                                <td>1:15PM - 2:10PM</td>
                                <td>Panel Discussion</td>
                                <td>55 min</td>
                                <td>Interactive session with panelists: Tao Yu, Roberta Raileanu, Alexandre Drouin, Denny Zhou, Graham Neubig, and Luke Zettlemoyer</td>
                              </tr>
                              <!-- Spotlight Presentation 5 -->
                              <tr class="evening-session">
                                <td>2:10PM - 2:20PM</td>
                                <td>Spotlight Presentation #5</td>
                                <td>10 mins</td>
                                <td>CodeAct</td>
                              </tr>
                              <!-- Spotlight Presentation 6 -->
                              <tr class="evening-session">
                                <td>2:20PM - 2:30PM</td>
                                <td>Spotlight Presentation #6</td>
                                <td>10 mins</td>
                                <td>Exploring Collaboration Mechanisms for LLM Agents</td>
                              </tr>
                              <!-- Poster -->
                              <tr class="evening-session">
                                <td>2:30PM - 3:30PM</td>
                                <td>Poster Session II, with Coffee</td>
                                <td>1 hr</td>
                                <td>Second session for display and discussion of all accepted submissions; Networking and refreshments</td>
                              </tr>
                              <!-- Invited Talk 5 -->
                              <tr class="evening-session">
                                <td>3:30PM - 4:00PM</td>
                                <td>Invited Talk #4</td>
                                <td>30 min</td>
                                <td>Chelsea Finn: Can AI agents learn from high-level feedback?</td>
                              </tr>
                              <!-- Invited Talk 6 -->
                              <tr class="evening-session">
                                <td>4:00PM - 4:30PM</td>
                                <td>Invited Talk #5</td>
                                <td>30 min</td>
                                <td>Karthik Narasimhan</td>
                              </tr>
                              <!-- Invited Talk 6 -->
                              <tr class="evening-session">
                                <td>4:30PM - 5:00PM</td>
                                <td>Invited Talk #6</td>
                                <td>30 min</td>
                                <td>Joyce Chai: LLMs in Connecting Humans and Embodied Agents</td>
                              </tr>
                              <!-- Closing Remarks -->
                              <tr class="night-session">
                                <td>5:00PM - 5:05PM</td>
                                <td>Closing Remarks</td>
                                <td>5 min</td>
                                <td>Concluding the workshop</td>
                              </tr>
                            </tbody>
                          </table>
                        </div>
                      </div>
                    </div>

                  </div>
                </section>

                <!-- End Workshop Schedule Section -->

                <!-- ======= CFP Section ======= -->
                <section id="cfp" class="cfp">
                  <div class="container">

                    <div class="section-title" data-aos="zoom-out">
                      <h2>Call for Papers</h2>
                    </div>

                    <div class="row">
                      <div class="col-lg-12">
                        <div class="cfp-details">
                          <h3>Important Dates:</h3>
                          <ul>
                            <li><strong>Submission Deadline:</strong> February
                              11th, 2024 (11:59 pm AoE)
                            </li>
                            <li><strong>Acceptance Notification:</strong>
                              <del>March 3rd, 2024</del> March 10th, 2024</li>

                            <li><strong>Camera Ready Deadline:</strong> April
                              20th, 2024</li>
                            <li><strong>Paper Availability on Website:</strong>
                              April
                              27th, 2024</li>
                            <li><strong>Workshop Date:</strong> May 11th,
                              2024</li>
                            <li><strong>Location:</strong> Vienna Exhibition &
                              Congress Center</li>
                          </ul>

                          <!-- Submission Tracks -->
                          <h3>Submission Tracks:</h3>

                          <p>Consistent with the themes of the workshop, we
                            invite
                            contributions in the areas <a
                              href="#topics">highlighted above</a>. However, we
                            emphasize that the topics list is not exhaustive and
                            welcome submissions in related areas. There is no
                            need to specify your track on OpenReview. Our
                            workshop will not accept work that has been
                            previously published in other conferences on machine
                            learning. Work that is presented at the main ICLR
                            conference should not be submitted to us as well.

                          </p>

                          <ul>
                            <li><strong>Research Paper Track:</strong> We
                              welcome a
                              variety of original research papers, including but
                              not limited to those
                              that propose new techniques, discussion-based
                              papers,
                              literature surveys, and position papers. Research
                              papers can have a <strong>maximum</strong> length
                              of up to 9
                              pages of content, plus unlimited pages
                              for references and appendix.</li>
                            <li><strong>Demo Paper Track:</strong> We also
                              welcome
                              technical reports for the demo track, with a
                              <strong>maximum</strong>
                              of 9 pages (same as research papers). In addition
                              to the
                              paper, please provide a link to a video, website,
                              or
                              code
                              repository showcasing your demo.</li>
                          </ul>

                          <!-- Guidelines Section -->
                          <h3>Submission Guidelines:</h3>
                          <ul>
                            <li>🌐 Submission Platform:
                              <ul>
                                <li>Submit your papers here: <strong><a
                                      href="https://openreview.net/group?id=ICLR.cc/2024/Workshop/LLMAgents">Openreview
                                      Submission
                                      Site</a></strong></li>
                              </ul>
                            </li>
                            <li>📄 Paper Requirements:
                              <ul>
                                <li>Use the provided <a
                                    href="https://github.com/ICLR/Master-Template/raw/master/iclr2024.zip">LaTeX
                                    template</a> for your
                                  submission.</li>
                                <li>Papers should be anonymized and uploaded as
                                  a
                                  single PDF.</li>
                                <li>📚 References and Appendix: Reviewers are
                                  not
                                  obliged to read the appendix.</li>
                              </ul>
                            </li>
                            <li>🔍 Non-Archival Policy:
                              <ul>
                                <li>Submissions will <strong>not be</strong>
                                  indexed or have archival proceedings. We
                                  welcome ICML 24 or ACL 24 submissions.</li>
                                <li>Accepted papers will be displayed on the
                                  workshop website on <strong>27th April
                                    2024</strong>. </li>
                              </ul>
                            </li>
                            <li>🔄 Dual Submission Policy:
                              <ul>
                                <li>Submissions under review at other venues
                                  will
                                  be accepted, provided they do not breach any
                                  dual-submission or anonymity policies of those
                                  venues.</li>
                              </ul>
                            </li>
                            <li>👀 Review Process:
                              <ul>
                                <li>The review process is double-blind.</li>
                              </ul>
                            </li>
                            <li>🏆 Best Paper Award:
                              <ul>
                                <li>The award for best paper will be
                                  announced at the
                                  workshop.</li>
                              </ul>
                            </li>
                          </ul>
                          <!-- End Guidelines Section -->

                        </div>
                      </div>
                    </div>

                  </div>
                </section>
                <!-- End CFP Section -->

                <!-- ======= Accepted Papers Section ======= -->
                <section id="accepted-papers" class="accepted-papers">
                  <div class="container">
                    <div class="section-title" data-aos="zoom-out">
                      <h2>Accepted Papers</h2>
                      <!-- <p>Explore the list of papers accepted for
                        presentation</p> -->
                    </div>
                    <div class="accordion" id="papersAccordion">
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingOral">
                          <button class="accordion-button collapsed"
                            type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseOral" aria-expanded="true"
                            aria-controls="collapseOral">
                            Oral Presentations
                          </button>
                        </h2>
                        <div id="collapseOral"
                          class="accordion-collapse collapse"
                          aria-labelledby="headingOral"
                          data-bs-parent="#papersAccordion">
                          <div class="accordion-body">
                            <!-- Paste the Oral presentations HTML list here -->
                            <ul><li><strong> AutoGen: Enabling Next-Gen LLM
                                  Applications via Multi-Agent
                                  Conversation</strong>, <br>Qingyun Wu, Gagan
                                Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang
                                Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,
                                Jiale Liu, Ahmed Hassan Awadallah, Ryen W White,
                                Doug Burger, Chi Wang</li>
                              <li><strong> Data-Copilot: Bridging Billions of
                                  Data and Humans with Autonomous
                                  Workflow</strong>, <br>Wenqi Zhang, Yongliang
                                Shen, Weiming Lu, Yueting Zhuang</li>
                              <li><strong> AutoAct: Automatic Agent Learning
                                  from Scratch via Self-Planning</strong>,
                                <br>Shuofei Qiao, Ningyu Zhang, Runnan Fang,
                                Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor
                                Jiang, chengfei lv, Huajun Chen</li>
                              <li><strong> Large Language Models can
                                  Strategically Deceive their Users when Put
                                  Under Pressure</strong>, <br>Jérémy Scheurer,
                                Mikita Balesni, Marius Hobbhahn</li>
                              <li><strong> Executable Code Actions Elicit Better
                                  LLM Agents</strong>, <br>Xingyao Wang, Yangyi
                                Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao
                                Peng, Heng Ji</li>
                              <li><strong> Exploring Collaboration Mechanisms
                                  for LLM Agents: A Social Psychology
                                  View</strong>, <br>Jintian Zhang, Xin Xu,
                                Ningyu Zhang, Ruibo Liu, Bryan Hooi, Shumin
                                Deng</li></ul>
                          </div>
                        </div>
                      </div>
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingPoster">
                          <button class="accordion-button collapsed"
                            type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapsePoster"
                            aria-expanded="false"
                            aria-controls="collapsePoster">
                            Poster Presentations
                          </button>
                        </h2>
                        <div id="collapsePoster"
                          class="accordion-collapse collapse"
                          aria-labelledby="headingPoster"
                          data-bs-parent="#papersAccordion">
                          <div class="accordion-body">
                            <!-- Paste the Poster presentations HTML list here -->
                            <ul><li><strong> Towards Unified Alignment Between
                                  Agents, Humans, and Environment</strong>,
                                <br>Zonghan Yang, An Liu, Zijun Liu, Kaiming
                                Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang,
                                Qingyuan Hu, XinRui Chen, Zhenhe Zhang, Fuwen
                                Luo, Zhicheng Guo, Peng Li, Yang Liu</li>
                              <li><strong> Self-Training Language Models in
                                  Arithmetic Reasoning</strong>, <br>Marek
                                Kadlčík, Michal Štefánik, Ondrej Sotolar,
                                Vlastimil Martinek</li>
                              <li><strong> R2E: Turning any Github Repository
                                  into a Programming Agent Test
                                  Environment</strong>, <br>Naman Jain, Manish
                                Shetty, Tianjun Zhang, King Han, Koushik Sen,
                                Ion Stoica</li>
                              <li><strong> Lumos: Learning Agents with Unified
                                  Data, Modular Design, and Open-Source
                                  LLMs</strong>, <br>Da Yin, Faeze Brahman,
                                Abhilasha Ravichander, Khyathi Chandu, Kai-Wei
                                Chang, Yejin Choi, Bill Yuchen Lin</li>
                              <li><strong> LEAGUE++: EMPOWERING CONTINUAL ROBOT
                                  LEARNING THROUGH GUIDED SKILL ACQUISITION WITH
                                  LARGE LANGUAGE MODELS</strong>, <br>Zhaoyi Li,
                                Kelin Yu, Shuo Cheng, Danfei Xu</li>
                              <li><strong> WavCraft: Audio Editing and
                                  Generation with Large Language
                                  Models</strong>, <br>Jinhua Liang, Huan Zhang,
                                Haohe Liu, Yin Cao, Qiuqiang Kong, Xubo Liu,
                                Wenwu Wang, Mark D Plumbley, Huy Phan, Emmanouil
                                Benetos</li>
                              <li><strong> SAGE: Bridging Semantic and
                                  Actionable Parts for Generalizable
                                  Manipulation of Articulated Objects</strong>,
                                <br>Haoran Geng, Songlin Wei, Congyue Deng,
                                Bokui Shen, He Wang, Leonidas Guibas</li>
                              <li><strong> Simulating Opinion Dynamics with
                                  Networks of LLM-based Agents</strong>,
                                <br>Yun-Shiuan Chuang, Agam Goyal, Nikunj
                                Harlalka, Siddharth Suresh, Robert D. Hawkins,
                                Sijia Yang, Dhavan V. Shah, Junjie Hu, Timothy
                                T. Rogers</li>
                              <li><strong> Agents: An Open-source Framework for
                                  Autonomous Language Agents</strong>,
                                <br>Wangchunshu Zhou, Yuchen Eleanor Jiang, Long
                                Li, Jialong Wu, Tiannan Wang, Shuai Wang, Jiamin
                                Chen, Jintian Zhang, Jing Chen, Xiangru Tang,
                                Peng Cui, Ningyu Zhang, Huajun Chen, Mrinmaya
                                Sachan</li>
                              <li><strong> A Human-Inspired Reading Agent with
                                  Gist Memory of Very Long Contexts</strong>,
                                <br>Kuang-Huei Lee, Xinyun Chen, Hiroki Furuta,
                                John Canny, Ian Fischer</li>
                              <li><strong> The Agent Ohana: Designing Unified
                                  Data and Training Pipeline for Effective Agent
                                  Learning</strong>, <br>Jianguo Zhang, Tian
                                Lan, Rithesh R N, Zhiwei Liu, Weiran Yao, Juntao
                                Tan, Yihao Feng, Thai Quoc Hoang, Tulika Manoj
                                Awalgaonkar, Liangwei Yang, Shelby Heinecke,
                                Huan Wang, Juan Carlos Niebles, Silvio Savarese,
                                Caiming Xiong</li>
                              <li><strong> Can Large Language Models be Good
                                  Path Planners? A Benchmark and Investigation
                                  on Spatial-temporal Reasoning</strong>,
                                <br>Mohamed Aghzal, Erion Plaku, Ziyu Yao</li>
                              <li><strong> FinMem: A Performance-Enhanced LLM
                                  Trading Agent with Layered Memory and
                                  Character Design</strong>, <br>Haohang Li,
                                Yangyang Yu, Zhi Chen, Yuechen Jiang, Yang Li,
                                Denghui Zhang, Rong Liu, Jordan W. Suchow,
                                Khaldoun Khashanah</li>
                              <li><strong> ArCHer: Training Language Model
                                  Agents via Hierarchical Multi-Turn
                                  RL</strong>, <br>Yifei Zhou, Andrea Zanette,
                                Jiayi Pan, Aviral Kumar, Sergey Levine</li>
                              <li><strong> Beyond A*: Better LLM planning via
                                  Search Dynamics Bootstrapping</strong>,
                                <br>Lucas Lehnert, Sainbayar Sukhbaatar, Paul
                                McVay, Michael Rabbat, Yuandong Tian</li>
                              <li><strong> A-CONECT: Designing AI-based
                                  Conversational Chatbot for Early Dementia
                                  Intervention</strong>, <br>Junyuan Hong,
                                Wenqing Zheng, Han Meng, Siqi Liang, Anqing
                                Chen, Hiroko H. Dodge, Jiayu Zhou, Zhangyang
                                Wang</li>
                              <li><strong> Agent Smith: A Single Image Can
                                  Jailbreak One Million Multimodal LLM Agents
                                  Exponentially Fast</strong>, <br>Xiangming Gu,
                                Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu,
                                Ye Wang, Jing Jiang, Min Lin</li>
                              <li><strong> Large Language Model Evaluation Via
                                  Multi AI Agents: Preliminary results</strong>,
                                <br>Zeeshan Rasheed, Muhammad Waseem, Kari
                                Systä, Pekka Abrahamsson</li>
                              <li><strong> Towards General Computer Control: A
                                  Multimodal Agent for Red Dead Redemption II as
                                  a Case Study</strong>, <br>Weihao Tan, Ziluo
                                Ding, Wentao Zhang, Boyu Li, Bohan Zhou, Junpeng
                                Yue, Haochong Xia, Jiechuan Jiang, Longtao
                                Zheng, Xinrun Xu, Yifei Bi, Pengjie Gu, Xinrun
                                Wang, Börje F. Karlsson, Bo An, Zongqing Lu</li>
                              <li><strong> GPT-4V(ision) is a Generalist Web
                                  Agent, if Grounded</strong>, <br>Boyuan Zheng,
                                Boyu Gou, Jihyung Kil, Huan Sun, Yu Su</li>
                              <li><strong> OpenAgents: An Open Platform for
                                  Language Agents in the Wild</strong>,
                                <br>Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng
                                Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua,
                                Junning Zhao, Qian Liu, Che Liu, Zeyu Liu,
                                Yiheng Xu, Hongjin SU, Dongchan Shin, Caiming
                                Xiong, Tao Yu</li>
                              <li><strong> OpenFMNav: Towards Open-Set Zero-Shot
                                  Object Navigation via Vision-Language
                                  Foundation Models</strong>, <br>Yuxuan Kuang,
                                Hai Lin, Meng Jiang</li>
                              <li><strong> TravelPlanner: A Benchmark for
                                  Real-World Planning with Language
                                  Agents</strong>, <br>Jian Xie, Kai Zhang,
                                Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong
                                Tian, Yanghua Xiao, Yu Su</li>
                              <li><strong> Empowering Autonomous Driving with
                                  Large Language Models: A Safety
                                  Perspective</strong>, <br>Yixuan Wang, Ruochen
                                Jiao, Simon Sinong Zhan, Chengtian Lang, Chao
                                Huang, Zhaoran Wang, Zhuoran Yang, Qi Zhu</li>
                              <li><strong> REX: Rapid Exploration and
                                  eXploitation for AI agents</strong>,
                                <br>Rithesh R N, Shelby Heinecke, Juan Carlos
                                Niebles, Zhiwei Liu, Le Xue, Weiran Yao, Yihao
                                Feng, Zeyuan Chen, Akash Gokul, Devansh Arpit,
                                Ran Xu, Phil L Mui, Huan Wang, Caiming Xiong,
                                Silvio Savarese</li>
                              <li><strong> Towards Natural Language-Driven
                                  Industrial Assembly Using Foundation
                                  Models</strong>, <br>Omkar Joglekar, Shir
                                Kozlovsky, Tal Lancewicki, Vladimir Tchuiev,
                                Zohar Feldman, Dotan Di Castro</li>
                              <li><strong> Mobile-Agent: Autonomous Multi-Modal
                                  Mobile Device Agent with Visual
                                  Perception</strong>, <br>Junyang Wang, Haiyang
                                Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang,
                                Fei Huang, Jitao Sang</li>
                              <li><strong> Exposing Limitations of Language
                                  Model Agents in Sequential-Task Compositions
                                  on the Web</strong>, <br>Hiroki Furuta, Yutaka
                                Matsuo, Aleksandra Faust, Izzeddin Gur</li>
                              <li><strong> LLM Reasoners: New Evaluation,
                                  Library, and Analysis of Step-by-Step
                                  Reasoning with Large Language Models</strong>,
                                <br>Shibo Hao, Yi Gu, Haotian Luo, Tianyang Liu,
                                Xiyan Shao, Xinyuan Wang, Shuhua Xie, Haodi Ma,
                                Adithya Samavedhi, Qiyue Gao, Zhen Wang, Zhiting
                                Hu</li>
                              <li><strong> R-Judge: Benchmarking Safety Risk
                                  Awareness for LLM Agents</strong>, <br>Tongxin
                                Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang,
                                Ruijie Zhao, Tian Xia, Lizhen Xu, Binglin Zhou,
                                Li Fangqi, Zhuosheng Zhang, Rui Wang, Gongshen
                                Liu</li>
                              <li><strong> LLF-Bench: Benchmark for Interactive
                                  Learning from Language Feedback</strong>,
                                <br>Ching-An Cheng, Andrey Kolobov, Dipendra
                                Misra, Allen Nie, Adith Swaminathan</li>
                              <li><strong> LLM-Deliberation: Evaluating LLMs
                                  with Interactive Multi-Agent Negotiation
                                  Game</strong>, <br>Sahar Abdelnabi, Amr Gomaa,
                                Sarath Sivaprasad, Lea Schönherr, Mario
                                Fritz</li>
                              <li><strong> Is it Possible to Edit Large Language
                                  Models Robustly?</strong>, <br>Xinbei Ma,
                                Tianjie Ju, Jiyang Qiu, Zhuosheng Zhang, hai
                                zhao, lifeng Liu, Yulong Wang</li>
                              <li><strong> Agent Instructs Large Language Models
                                  to be General Zero-Shot Reasoners</strong>,
                                <br>Nicholas Crispino, Kyle Montgomery, Fankun
                                Zeng, Dawn Song, Chenguang Wang</li>
                              <li><strong> WorkArena: How Capable are Web Agents
                                  at Solving Common Knowledge Work
                                  Tasks?</strong>, <br>Alexandre Drouin, Maxime
                                Gasse, Massimo Caccia, Issam H. Laradji, Manuel
                                Del Verme, Tom Marty, David Vazquez, Nicolas
                                Chapados, Alexandre Lacoste</li>
                              <li><strong> Corex: Pushing the Boundaries of
                                  Complex Reasoning through Multi-Model
                                  Collaboration</strong>, <br>Qiushi Sun,
                                Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu,
                                Lingpeng Kong</li>
                              <li><strong> ProtAgents: Protein discovery via
                                  large language model multi-agent
                                  collaborations combining physics and machine
                                  learning</strong>, <br>Alireza Ghafarollahi,
                                Markus Buehler</li>
                              <li><strong> Hierarchical Auto-Organizing System
                                  for Open-Ended Multi-Agent
                                  Navigation</strong>, <br>Zhonghan Zhao, Kewei
                                Chen, Dongxu Guo, Wenhao Chai, Tian Ye, Yanting
                                Zhang, Gaoang Wang</li>
                              <li><strong> EHRAgent: Code Empowers Large
                                  Language Models for Few-shot Complex Tabular
                                  Reasoning on Electronic Health
                                  Records</strong>, <br>Wenqi Shi, Ran Xu,
                                Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu,
                                Yuanda Zhu, Joyce C. Ho, Carl Yang, May Dongmei
                                Wang</li>
                              <li><strong> Uncertainty of Thoughts:
                                  Uncertainty-Aware Planning Enhances
                                  Information Seeking in Large Language
                                  Models</strong>, <br>Zhiyuan Hu, Chumin Liu,
                                Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan
                                Luu, Junxian He, Pang Wei Koh, Bryan Hooi</li>
                              <li><strong> TaskBench: Benchmarking Large
                                  Language Models for Task Automation</strong>,
                                <br>Yongliang Shen, Kaitao Song, Xu Tan, Wenqi
                                Zhang, Kan Ren, Siyu Yuan, Weiming Lu, Dongsheng
                                Li, Yueting Zhuang</li>
                              <li><strong> SELF-IMAGINE: Effective Unimodal
                                  Reasoning with Multimodal Models using
                                  Self-Imagination</strong>, <br>Syeda Nahida
                                Akter, Aman Madaan, Sangwu Lee, Yiming Yang,
                                Eric Nyberg</li>
                              <li><strong> BioDiscoveryAgent: An AI Agent for
                                  Designing Genetic Perturbation
                                  Experiments</strong>, <br>Yusuf H Roohani,
                                Jian Vora, Qian Huang, Percy Liang, Jure
                                Leskovec</li>
                              <li><strong> MAGIC: INVESTIGATION OF LARGE
                                  LANGUAGE MODEL POWERED MULTI-AGENT IN
                                  COGNITION, ADAPTABILITY, RATIONALITY AND
                                  COLLABORATION</strong>, <br>Lin Xu, Zhiyuan
                                Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt
                                Keutzer, See-Kiong Ng, Jiashi Feng</li>
                              <li><strong> Do LLM Agents Have Regret? A Case
                                  Study in Online Learning and Games</strong>,
                                <br>Chanwoo Park, Xiangyu Liu, Asuman E.
                                Ozdaglar, Kaiqing Zhang</li>
                              <li><strong> Prioritizing Safeguarding Over
                                  Autonomy: Risks of LLM Agents for
                                  Science</strong>, <br>Xiangru Tang, Qiao Jin,
                                Kunlun Zhu, Tongxin Yuan, Yichi Zhang,
                                Wangchunshu Zhou, Meng Qu, Yilun Zhao, Jian
                                Tang, Zhuosheng Zhang, Arman Cohan, Zhiyong Lu,
                                Mark Gerstein</li>
                              <li><strong> Expressing and Exploiting Parallelism
                                  in Language Model Decoding</strong>, <br>Tian
                                Jin, Ellie Y Cheng, Michael Carbin</li>
                              <li><strong> Towards Self-Improving Language
                                  Models for Code Generation</strong>,
                                <br>Michaël Defferrard, Corrado Rainone, David
                                W. Zhang, Blazej Manczak, Natasha Butt, Taco
                                Cohen</li>
                              <li><strong> MathChat: Converse to Tackle
                                  Challenging Math Problems with LLM
                                  Agents</strong>, <br>Yiran Wu, Feiran Jia,
                                Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang,
                                Yin Tat Lee, Richard Peng, Qingyun Wu, Chi
                                Wang</li>
                              <li><strong> L3GO: Language Agents with
                                  Chain-of-3D-Thoughts for Generating
                                  Unconventional Objects</strong>, <br>Yutaro
                                Yamada, Khyathi Chandu, Bill Yuchen Lin, Jack
                                Hessel, Ilker Yildirim, Yejin Choi</li>
                              <li><strong> An Embodied Generalist Agent in 3D
                                  World</strong>, <br>Jiangyong Huang, Silong
                                Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li,
                                Yan Wang, Qing Li, Song-Chun Zhu, Baoxiong Jia,
                                Siyuan Huang</li>
                              <li><strong> Agent-Pro: Learning to Evolve via
                                  Policy-Level Reflection and
                                  Optimization</strong>, <br>Wenqi Zhang, Ke
                                Tang, Hai Wu, Mengna Wang, Yongliang Shen,
                                Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang,
                                Weiming Lu</li>
                              <li><strong> Recursive Speculative Decoding:
                                  Accelerating LLM Inference via Sampling
                                  Without Replacement</strong>, <br>Wonseok
                                Jeon, Mukul Gagrani, Raghavv Goel, Junyoung
                                Park, Mingu Lee, Christopher Lott</li>
                              <li><strong> VisualWebArena: Evaluating Multimodal
                                  Agents on Realistic Visual Web Tasks</strong>,
                                <br>Jing Yu Koh, Robert Lo, Lawrence Jang,
                                Vikram Duvvur, Ming Chong Lim, Po-Yu Huang,
                                Graham Neubig, Shuyan Zhou, Ruslan
                                Salakhutdinov, Daniel Fried</li>
                              <li><strong> HELPER-X: A Unified Instructable
                                  Embodied Agent to Tackle Four Interactive
                                  Vision-Language Domains with Memory-Augmented
                                  Language Models</strong>, <br>Gabriel Herbert
                                Sarch, Sahil Somani, Raghav Kapoor, Michael J.
                                Tarr, Katerina Fragkiadaki</li>
                              <li><strong> Controlling Large Language
                                  Model-based Agents for Large-Scale
                                  Decision-Making: An Actor-Critic
                                  Approach</strong>, <br>Bin Zhang, Hangyu Mao,
                                Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang,
                                Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, Lijuan
                                Li, Guoliang Fan</li>
                              <li><strong> Plan-Seq-Learn: Language Model Guided
                                  RL for Solving Long Horizon Robotics
                                  Tasks</strong>, <br>Murtaza Dalal, Tarun
                                Chiruvolu, Devendra Singh Chaplot, Ruslan
                                Salakhutdinov</li>
                              <li><strong> Adapting Uni-Modal Language Models
                                  for Dense Multi-Modal Co-Reference Resolution
                                  using Parameter Augmentation</strong>,
                                <br>Samuel Osebe, Prashan Wanigasekara, Thanh
                                Tran, Thomas Gueudre</li>
                              <li><strong> Preference-Conditioned
                                  Language-Guided Abstraction</strong>, <br>Andi
                                Peng, Andreea Bobu, Belinda Z. Li, Theodore
                                Sumers, Ilia Sucholutsky, Nishanth Kumar, Thomas
                                L. Griffiths, Julie Shah</li>
                              <li><strong> S-Agent: self-organizing agents in
                                  open-ended environment</strong>, <br>Jiaqi
                                Chen, Yuxian Jiang, Jiachen Lu, Li Zhang</li>
                              <li><strong> Efficient Human-AI Coordination via
                                  Preparatory Language-based
                                  Convention</strong>, <br>Cong Guan, Lichao
                                Zhang, Chunpeng Fan, Yi-Chen Li, Feng Chen, Lihe
                                Li, Yunjia Tian, Lei Yuan, Yang Yu</li>
                              <li><strong> SeeClick: Harnessing GUI Grounding
                                  for Advanced Visual GUI Agents</strong>,
                                <br>Kanzhi Cheng, Qiushi Sun, Yougang Chu,
                                Fangzhi Xu, Li YanTao, Jianbing Zhang, Zhiyong
                                Wu</li>
                              <li><strong> The ART of LLM Refinement: Ask,
                                  Refine, Trust</strong>, <br>Kumar
                                Shridhar</li>
                              <li><strong> SceneCraft: An LLM Agent for
                                  Synthesizing 3D Scene as Blender
                                  Code</strong>, <br>Ziniu Hu</li>
                              <li><strong> LangProp: A code optimization
                                  framework using Large Language Models applied
                                  to driving</strong>, <br>Shu Ishida, Gianluca
                                Corrado, George Fedoseev, Hudson Yeo, Lloyd
                                Russell, Jamie Shotton, Joao F. Henriques,
                                Anthony Hu</li>
                              <li><strong> FL-TAC: Enhanced Fine-Tuning in
                                  Federated Learning via Low-Rank, Task-Specific
                                  Adapter Clustering</strong>, <br>Siqi Ping,
                                Yuzhu Mao, Yang Liu, Xiao-Ping Zhang, Wenbo
                                Ding</li>
                              <li><strong> EcoAssistant: Using LLM Assistants
                                  More Affordably and Accurately</strong>,
                                <br>Jieyu Zhang, Ranjay Krishna, Ahmed Hassan
                                Awadallah, Chi Wang</li>
                              <li><strong> IntentGPT: Few-shot Intent Discovery
                                  with Large Language Models</strong>, <br>Juan
                                A. Rodriguez, Nicholas Botzer, David Vazquez,
                                Christopher Pal, Marco Pedersoli, Issam H.
                                Laradji</li>
                              <li><strong> Language-guided Skill Learning with
                                  Temporal Variational Inference</strong>,
                                <br>Haotian Fu, Pratyusha Sharma, Elias
                                Stengel-Eskin, George Konidaris, Nicolas Le
                                Roux, Marc-Alexandre Côté, Xingdi Yuan</li>
                              <li><strong> Decision-Oriented Dialogue for
                                  Human-AI Collaboration</strong>, <br>Jessy
                                Lin, Nicholas Tomlin, Jacob Andreas, Jason
                                Eisner</li>
                              <li><strong> Making Retrieval-Augmented Language
                                  Models Robust to Irrelevant Context</strong>,
                                <br>Ori Yoran, Tomer Wolfson, Ori Ram, Jonathan
                                Berant</li>
                              <li><strong> MedAgents: Large Language Models as
                                  Collaborators for Zero-shot Medical
                                  Reasoning</strong>, <br>Xiangru Tang, Anni
                                Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao,
                                Xingyao Zhang, Arman Cohan, Mark Gerstein</li>
                              <li><strong> Collaborative LLM-Agents for Editable
                                  Driving Scene Simulation</strong>, <br>Yuxi
                                Wei, Zi Wang, Yifan Lu, Chenxin Xu, Changxing
                                Liu, Hao Zhao, Siheng Chen, Yanfeng Wang</li>
                              <li><strong> WebLINX: Real-World Website
                                  Navigation with Multi-Turn Dialogue</strong>,
                                <br>Xing Han Lu, Zdeněk Kasner, Siva Reddy</li>
                              <li><strong> The Wisdom of Partisan Crowds:
                                  Comparing Collective Intelligence in Humans
                                  and LLM-based Agents</strong>, <br>Yun-Shiuan
                                Chuang, Nikunj Harlalka, Siddharth Suresh, Agam
                                Goyal, Robert D. Hawkins, Sijia Yang, Dhavan V.
                                Shah, Junjie Hu, Timothy T. Rogers</li>
                              <li><strong> BOLAA: BENCHMARKING AND ORCHESTRATING
                                  LLM AUTONOMOUS AGENTS</strong>, <br>Zhiwei
                                Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby
                                Heinecke, Rithesh R N, Yihao Feng, Zeyuan Chen,
                                Juan Carlos Niebles, Devansh Arpit, Ran Xu, Phil
                                L Mui, Huan Wang, Caiming Xiong, Silvio
                                Savarese</li>
                              <li><strong> Boosting Task Planning and Tool Usage
                                  of Large Language Model-based Agents in
                                  Real-world Systems</strong>, <br>Yilun Kong,
                                Jingqing Ruan, YiHong Chen, Bin Zhang, Tianpeng
                                Bao, shi shiwei, du guo qing, xiaoru hu, Hangyu
                                Mao, Ziyue Li, Xingyu Zeng, Rui Zhao, Xueqian
                                Wang</li>
                              <li><strong> Self-Alignment of Large Language
                                  Models via Multi-Agent Social
                                  Simulation</strong>, <br>Xianghe Pang, Shuo
                                Tang, Rui Ye, Yuxin Xiong, Bolun Zhang, Yanfeng
                                Wang, Siheng Chen</li>
                              <li><strong> If LLM Is the Wizard, Then Code Is
                                  the Wand: A Survey on How Code Empowers Large
                                  Language Models to Serve as Intelligent
                                  Agents</strong>, <br>Ke Yang, Jiateng Liu,
                                John Wu, Chaoqi Yang, Yi Fung, Sha Li, Zixuan
                                Huang, Xu Cao, Xingyao Wang, Heng Ji, ChengXiang
                                Zhai</li>
                              <li><strong> ReST meets ReAct: Self-Improvement
                                  for Multi-Step Reasoning LLM Agent</strong>,
                                <br>Renat Aksitov, Sobhan Miryoosefi, Zonglin
                                Li, Daliang Li, Sheila Babayan, Kavya Kopparapu,
                                Zachary Fisher, Ruiqi Guo, Sushant Prakash,
                                Pranesh Srinivasan, Manzil Zaheer, Felix Yu,
                                Sanjiv Kumar</li>
                              <li><strong> Are Machines Better at Slow Thinking?
                                  Unveiling Human-Machine Inference Gaps in
                                  Entailment Verification</strong>, <br>Soumya
                                Sanyal, Tianyi Xiao, Jiacheng Liu, Wenya Wang,
                                Xiang Ren</li>
                              <li><strong> Limitations of Agents Simulated by
                                  Predictive Models</strong>, <br>Raymond
                                Douglas, Jacek Karwowski, Chan Bae, Andis
                                Draguns, Victoria Krakovna</li>
                              <li><strong> OS-Copilot: Towards Generalist
                                  Computer Agents with
                                  Self-Improvement</strong>, <br>Zhiyong Wu,
                                Chengcheng Han, Zichen Ding, Zhenmin Weng,
                                Zhoumianze Liu, Shunyu Yao, Tao Yu, Lingpeng
                                Kong</li>
                              <li><strong> EASYTOOL: Enhancing LLM-based Agents
                                  with Concise Tool Instruction</strong>,
                                <br>Siyu Yuan, Kaitao Song, Jiangjie Chen, Xu
                                Tan, Yongliang Shen, Kan Ren, Dongsheng Li,
                                Deqing Yang</li>
                              <li><strong> FLASK: Fine-grained Language Model
                                  Evaluation based on Alignment Skill
                                  Sets</strong>, <br>Seonghyeon Ye, Doyoung Kim,
                                Sungdong Kim, Hyeonbin Hwang, Seungone Kim,
                                Yongrae Jo, James Thorne, Juho Kim, Minjoon
                                Seo</li>
                              <li><strong> Language Agent Tree Search Unifies
                                  Reasoning Acting and Planning in Language
                                  Models</strong>, <br>Andy Zhou, Kai Yan,
                                Michal Shlapentokh-Rothman, Haohan Wang,
                                Yu-Xiong Wang</li>
                              <li><strong> On the Road with GPT-4V(ision):
                                  Explorations of Utilizing Visual-Language
                                  Model as Autonomous Driving Agent</strong>,
                                <br>Licheng Wen, Xuemeng Yang, Daocheng Fu,
                                Xiaofeng Wang, Pinlong Cai, Xin Li, Tao MA,
                                Yingxuan Li, Linran XU, Dengke Shang, Zheng Zhu,
                                Shaoyan Sun, Yeqi BAI, Xinyu Cai, Min Dou,
                                Shuanglu Hu, Botian Shi, Yu Qiao</li>
                              <li><strong> Bring Your Own KG: Self-Supervised
                                  Program Synthesis for Zero-Shot KGQA</strong>,
                                <br>Dhruv Agarwal, Rajarshi Das, Sopan Khosla,
                                Rashmi Gangadharaiah</li>
                              <li><strong> Open-TI: Open Traffic Intelligence
                                  with Augmented Language Model</strong>,
                                <br>Longchao Da, Kuan-Ru Liou, Tiejin Chen,
                                Xuesong Zhou, Xiangyong Luo, Yezhou Yang, Hua
                                Wei</li>
                              <li><strong> AgentBoard: An Analytical Evaluation
                                  Board of Multi-turn LLM Agents</strong>,
                                <br>Chang Ma, Junlei Zhang, Zhihao Zhu, Cheng
                                Yang, Yujiu Yang, Yaohui Jin, Zhenzhong Lan,
                                Lingpeng Kong, Junxian He</li></ul>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </section><!-- End Accepted Papers Section -->

                <!-- ======= Organization Section ======= -->
                <section id="org" class="team">
                  <div class="container">

                    <div class="section-title" data-aos="zoom-out">
                      <h2>Organization</h2>
                      <p>Workshop Organizers</p>
                    </div>

                    <div class="section-title" data-aos="zoom-out">
                      <h3>Organizing Commitee</h3>
                    </div>

                    <div class="row">

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img src="assets/img/organizer/Xinyun.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://jungyhuk.github.io/">Xinyun
                                Chen</a></h4>
                            <strong>Senior Research Scientist, Google
                              DeepMind</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img src="assets/img/photo-xiangru.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://xiangrutang.github.io/">Xiangru
                                Robert Tang</a></h4>
                            <strong>Ph.D. student @ Yale University</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img src="assets/img/di.jpg" class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://jind11.github.io/">Di
                                Jin</a></h4>
                            <strong>Senior Applied Scientist @ Amazon</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img src="assets/img/organizer/dev.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://www.devamanyu.com/">Devamanyu
                                Hazarika</a></h4>
                            <strong>Applied Scientist @ Amazon</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img
                              src="https://scsdean.cs.cmu.edu/new-faculty/resources/2022/daniel_fried.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://dpfried.github.io/">Daniel
                                Fried</a></h4>
                            <strong>Assistant Professor, CMU LTI</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img src="assets/img/organizer/song.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a
                                href="https://www2.eecs.berkeley.edu/Faculty/Homepages/song.html">Dawn
                                Song</a></h4>
                            <strong>Professor, University of California,
                              Berkeley </strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img
                              src="data:image/jpeg;base64,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"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a href="https://raihanjoty.github.io/">Shafiq
                                Joty</a></h4>
                            <strong>Research Director, Salesforce
                              Research</strong>
                          </div>
                        </div>
                      </div>

                      <div class="col-lg-2 col-md-6 d-flex align-items-stretch">
                        <div class="member" data-aos="fade-up">
                          <div class="member-img">
                            <img
                              src="assets/img/organizer/merriemorris_square.jpg"
                              class="img-fluid" alt>
                          </div>
                          <div class="member-info">
                            <h4><a
                                href="https://cs.stanford.edu/~merrie/">Meredith
                                Ringel Morris </a></h4>
                            <strong>Director for Human-AI Interaction Research,
                              Google DeepMind</strong>
                          </div>
                        </div>
                      </div>

                    </div>
                  </div>

                </section><!-- End Organization Section -->

                <!-- ======= Reviewers Section ======= -->
                <section id="reviewers" class="reviewers">
                  <div class="container">
                    <div class="section-title" data-aos="zoom-out">
                      <h2>Program Committee</h2>
                    </div>
                    <div class="accordion" id="reviewersAccordion">
                      <div class="accordion-item">
                        <h2 class="accordion-header" id="headingReviewer">
                          <button class="accordion-button collapsed"
                            type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseReviewer" aria-expanded="true"
                            aria-controls="collapseReviewer">
                            Reviewers
                          </button>
                        </h2>
                        <div id="collapseReviewer"
                          class="accordion-collapse collapse"
                          aria-labelledby="headingReviewer"
                          data-bs-parent="#papersAccordion">
                          <div class="accordion-body">

                            <div class="row">
                              <div class="col-lg-12">
                                <ul class="list-unstyled">
                                  <li>Yuelyu Ji, <it>University of
                                      Pittsburgh</it></li>
                                  <li>Hangyu Mao, <it>Sensetime
                                      Research</it></li>
                                  <li>Boyuan Zheng, <it>Ohio State University,
                                      Columbus</it></li>
                                  <li>Siyu Yuan, <it>Fudan University</it></li>
                                  <li>Xin Cong, <it>Tsinghua University,
                                      Tsinghua
                                      University</it></li>
                                  <li>Markus Buehler, <it>Massachusetts
                                      Institute of
                                      Technology</it></li>
                                  <li>Lin Xu, <it>National University of
                                      Singapore</it></li>
                                  <li>Chenfei Yuan, <it>Department of Computer
                                      Science
                                      and Technology, Tsinghua
                                      University</it></li>
                                  <li>Haochen Vector Zhao, <it>Peking
                                      University</it></li>
                                  <li>Feiran Jia, <it>Pennsylvania State
                                      University</it></li>
                                  <li>Yao Yao, <it>Shanghai Jiaotong
                                      University</it></li>
                                  <li>Zhang Ruichen, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Mathieu Ravaut, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Zirui Zhao, <it>national university of
                                      singaore,
                                      National University of Singapore</it></li>
                                  <li>Jialong Wu, <it>Southeast
                                      University</it></li>
                                  <li>Rithesh R N, <it>SalesForce.com</it></li>
                                  <li>Juntao Tan, <it>Rutgers
                                      University</it></li>
                                  <li>Ting Chen, <it>University of Electronic
                                      Science
                                      and Technology of China</it></li>
                                  <li>Yun-Shiuan Chuang, <it>University of
                                      Wisconsin -
                                      Madison</it></li>
                                  <li>Jiageng Mao, <it>University of Southern
                                      California</it></li>
                                  <li>Yongliang Shen, <it>Microsoft</it></li>
                                  <li>Zhiruo Wang, <it>Carnegie Mellon
                                      University</it></li>
                                  <li>Jiuzhou Han, <it>Monash
                                      University</it></li>
                                  <li>Kaixin Ma, <it>Tencent AI Lab</it></li>
                                  <li>Hao Peng, <it>Department of Computer
                                      Science,
                                      University of Illinois
                                      Urbana-Champaign</it></li>
                                  <li>Jian Guan, <it>Tsinghua University,
                                      Tsinghua
                                      University</it></li>
                                  <li>Shaoguang Mao, <it>Microsoft</it></li>
                                  <li>Olivia Watkins, <it>University of
                                      California
                                      Berkeley</it></li>
                                  <li>Jiateng Liu, <it>Department of Computer
                                      Science</it></li>
                                  <li>Qian Huang, <it>Google</it></li>
                                  <li>Haozhe Zhao, <it>Peking
                                      University</it></li>
                                  <li>Yecheng Jason Ma, <it>University of
                                      Pennsylvania</it></li>
                                  <li>Zhenran Xu, <it>Harbin Institute of
                                      Technology,
                                      Shenzhen</it></li>
                                  <li>Zhongshen Zeng, <it>Department of Computer
                                      Science
                                      and Engineering, The Chinese University of
                                      Hong
                                      Kong</it></li>
                                  <li>Kuang-Huei Lee, <it>Google</it></li>
                                  <li>Chunyuan Deng, <it>Georgia Institute of
                                      Technology</it></li>
                                  <li>Meghana Moorthy Bhat, <it>Salesforce
                                      Research</it></li>
                                  <li>Tianjun Zhang, <it>University of
                                      California
                                      Berkeley</it></li>
                                  <li>Jiangyong Huang, <it>Peking
                                      University</it></li>
                                  <li>Wenshan Wu, <it>Microsoft</it></li>
                                  <li>Kimin Lee, <it>Korea Advanced Institute of
                                      Science
                                      & Technology</it></li>
                                  <li>Daquan Zhou, <it>Bytedance</it></li>
                                  <li>Haoqi Yuan, <it>Peking
                                      University</it></li>
                                  <li>Osbert Bastani, <it>University of
                                      Pennsylvania</it></li>
                                  <li>Shuyan Zhou, <it>Carnegie Mellon
                                      University</it></li>
                                  <li>Agam Goyal, <it>University of Wisconsin -
                                      Madison</it></li>
                                  <li>Gang Qiao, <it>Siemens
                                      Healthineers</it></li>
                                  <li>Xun Wang, <it>Microsoft</it></li>
                                  <li>Sahitya Potluri, <it>Google</it></li>
                                  <li>Xingyao Wang, <it>Department of Computer
                                      Science,
                                      University of Illinois
                                      Urbana-Champaign</it></li>
                                  <li>Wenyue Hua, <it>Rutgers University, New
                                      Brunswick</it></li>
                                  <li>Younggyo Seo, <it>Dyson</it></li>
                                  <li>Zhangcheng Qiang, <it>Australian National
                                      University</it></li>
                                  <li>Boyu Gou, <it>Ohio State University,
                                      Columbus</it></li>
                                  <li>Jian Xie, <it>Fudan University</it></li>
                                  <li>Ziniu Hu, <it>California Institute of
                                      Technology</it></li>
                                  <li>Yichi Zhang, <it>Peking
                                      University</it></li>
                                  <li>Fangkai Jiao, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Yangyi Chen, <it>School of Computer
                                      Science,
                                      University of Illinois at
                                      Urbana-Champaign</it></li>
                                  <li>Ravi Pandya, <it>Carnegie Mellon
                                      University</it></li>
                                  <li>Zelong Li, <it>Rutgers University, New
                                      Brunswick</it></li>
                                  <li>Jiayuan Mao, <it>Massachusetts Institute
                                      of
                                      Technology</it></li>
                                  <li>Bohan Lyu, <it>Tsinghua
                                      University</it></li>
                                  <li>Senbao Shi, <it>Harbin Institute of
                                      Technology</it></li>
                                  <li>Kaitao Song, <it>Microsoft</it></li>
                                  <li>Nikunj Harlalka, <it>University of
                                      Wisconsin -
                                      Madison</it></li>
                                  <li>Zhihan Liu, <it>Northwestern
                                      University</it></li>
                                  <li>Haochun Wang, <it>Harbin Institute of
                                      Technology</it></li>
                                  <li>Chi Zhang, <it>Tencent </it></li>
                                  <li>Chang Gao, <it>The Chinese University of
                                      Hong
                                      Kong</it></li>
                                  <li>Kun Shao, <it>Huawei Noah's Ark
                                      Lab</it></li>
                                  <li>Lanqing Li, <it>Zhejiang Lab</it></li>
                                  <li>Ziyuan Qin, <it>Case Western Reserve
                                      University</it></li>
                                  <li>Chengjie Zheng, <it>University of
                                      Massachusetts
                                      Boston</it></li>
                                  <li>Bharat Prakash, <it>University of
                                      Maryland,
                                      Baltimore County</it></li>
                                  <li>Yanjun Shao, <it>Fudan
                                      University</it></li>
                                  <li>Amrita Saha, <it>SalesForce.com</it></li>
                                  <li>Ke Yang, <it>Department of Computer
                                      Science</it></li>
                                  <li>Zhao Xu, <it>Hong Kong University of
                                      Science and
                                      Technology</it></li>
                                  <li>Ruochen Zhao, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Chaoqi Yang, <it>University of Illinois
                                      Urbana
                                      Champaign</it></li>
                                  <li>Hao Wang, <it>Google</it></li>
                                  <li>Yangyang Yu, <it>Stevens Institute of
                                      Technology</it></li>
                                  <li>Shuofei Qiao, <it>Zhejiang
                                      University</it></li>
                                  <li>Hailin Chen, <it>National Technological
                                      University</it></li>
                                  <li>Yuan Yao, <it>Nanjing University</it></li>
                                  <li>Lei Liu, <it>The Chinese University of
                                      Hong Kong,
                                      Shenzhen</it></li>
                                  <li>Yuechen Jiang, <it>Stevens Institute of
                                      Technology</it></li>
                                  <li>Pengguang Chen, <it>SmartMore</it></li>
                                  <li>Chuan Xiao, <it>Osaka University</it></li>
                                  <li>Sha Li, <it>University of Illinois, Urbana
                                      Champaign</it></li>
                                  <li>Wenqi Zhang, <it>Zhejiang
                                      University</it></li>
                                  <li>Yilun Zhao, <it>Yale University</it></li>
                                  <li>Kaikai An, <it>Peking University</it></li>
                                  <li>Yunhao Yang, <it>University of Texas at
                                      Austin</it></li>
                                  <li>Haohang Li, <it>Stevens Institute of
                                      Technology</it></li>
                                  <li>Jianghao Zhang, <it>University of Michigan
                                      - Ann
                                      Arbor</it></li>
                                  <li>Shruti Singh, <it>IIT
                                      Gandhinagar</it></li>
                                  <li>Zhi Chen, <it>Stevens Institute of
                                      Technology</it></li>
                                  <li>He Zhu, <it>Rutgers University</it></li>
                                  <li>Allen Nie, <it>Stanford
                                      University</it></li>
                                  <li>Shuzheng Si, <it>Peking
                                      University</it></li>
                                  <li>Muhammad Waseem, <it>University of
                                      Jyväskylä</it></li>
                                  <li>Jing Yu Koh, <it>Carnegie Mellon
                                      University</it></li>
                                  <li>Kunlun Zhu, <it>Université de
                                      Montréal</it></li>
                                  <li>Chengwei Qin, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Zengqing Wu, <it>Kyoto
                                      University</it></li>
                                  <li>Vernon Bumgardner, <it>University of
                                      Kentucky</it></li>
                                  <li>Chenyang Zhao, <it>Zhejiang Lab</it></li>
                                  <li>Rong Liu, <it>Stevens Institute of
                                      Technology</it></li>
                                  <li>Sihao Hu, <it>Georgia Institute of
                                      Technology</it></li>
                                  <li>Srijan Bansal, <it>Carnegie Mellon
                                      University</it></li>
                                  <li>Da Yin, <it>University of California, Los
                                      Angeles</it></li>
                                  <li>Hung Le, <it>Salesforce Research</it></li>
                                  <li>Enxhell Luzhnica, <it>Google</it></li>
                                  <li>Michelle D Zhao, <it>CMU, Carnegie Mellon
                                      University</it></li>
                                  <li>Yunfan Jiang, <it>Stanford
                                      University</it></li>
                                  <li>Hongyang Du, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Jason Phang, <it>New York
                                      University</it></li>
                                  <li>Xingxuan Li, <it>Nanyang Technological
                                      University</it></li>
                                  <li>Mingqi Gao, <it>Peking
                                      University</it></li>
                                  <li>Xiao Han, <it>Peking University</it></li>
                                  <li>Haojie Pan, <it>Department of Computer
                                      Science and
                                      Engineering, Hong Kong University of
                                      Science and
                                      Technology</it></li>
                                  <li>Pekka Abrahamsson, <it>Tampere
                                      University</it></li>
                                  <li>Haibin Huang, <it>Kuaishou
                                      Technology</it></li>
                                  <li>Yiming Zhang, <it>Tokyo Institute of
                                      Technology,
                                      Tokyo Institute of Technology</it></li>
                                  <li>Baotian Hu, <it>Harbin Institute of
                                      Technology,
                                      Shenzhen</it></li>
                                  <li>Yang Yuan, <it>Tsinghua University,
                                      Tsinghua
                                      University</it></li>
                                  <li>Yixin Zhang, <it>Kyoto University, Kyoto
                                      University</it></li>
                                  <li>Riccardo Cantini, <it>University of
                                      Calabria</it></li>
                                  <li>Tiankai Hang, <it>Southeast
                                      University</it></li>
                                  <li>Gongshen Liu, <it>Shanghai Jiao Tong
                                      University</it></li>
                                  <li>Yuzhou Du, <it>Northwestern
                                      University</it></li>
                                  <li>Xiaocheng Lu, <it>Hong Kong Polytechnic
                                      University</it></li>
                                  <li>Sarang Gupta, <it>Asana</it></li>
                                  <li>Inderjeet Jayakumar Nair, <it>University
                                      of
                                      Michigan - Ann Arbor</it></li>
                                  <li>Gabrielle Kaili-May Liu, <it>Department of
                                      Computer Science, Yale
                                      University</it></li>
                                  <li>Shuyuan Zheng, <it>Osaka
                                      University</it></li>
                                  <li>Run Peng, <it>University of Michigan - Ann
                                      Arbor</it></li>
                                  <li>Mira Moukheiber, <it>Massachusetts
                                      Institute of
                                      Technology</it></li>
                                  <li>John Wu, <it>University of Illinois at
                                      Urbana-Champaign</it></li>
                                  <li>Bin Liu, <it>Zhejiang Lab</it></li>
                                </ul>
                              </div>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </section><!-- End Reviewers Section -->




                <!-- ======= Contact Section ======= -->
                <section id="award" class="award">
                  <div class="container">

                    <div class="section-title" data-aos="zoom-out">
                      <h2>Award</h2>
                    </div>
                    <div>
                      <h5>The Best Paper Award:
                        <br><br>
                        AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation

        <br><br>
                        Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger, Chi Wang

                        </h5>

                    </div>

                  </div>

                </section><!-- End Contact Section -->












              
                <!-- ======= Contact Section ======= -->
                <section id="contact" class="contact">
                  <div class="container">

                    <div class="section-title" data-aos="zoom-out">
                      <h2>Contact us</h2>
                    </div>
                    <div>
                      <h5>Email us at <a
                          href="mailto:llm.agents.ws@gmail.com">llm.agents.ws@gmail.com</a>
                        | <a
                          href="mailto:xiangru.tang@yale.edu">xiangru.tang@yale.edu</a></h5>

                    </div>

                  </div>

                </section><!-- End Contact Section -->

                <!-- ======= Contact Section ======= -->
               <section id="sponsors" class="sponsors">
      <div class="container">

        <div class="section-title" data-aos="zoom-out">
          <h2>Sponsors</h2>
        </div>

      <p>  
      <a href="https://www.multion.ai/">MultiOn AI</a>
      </p>
<br>

                        <div class="member-img">
                          <img src="assets/img/multion_logo.jpeg"
                            class="img-fluid" alt>
                        </div>

<br><br>
        <p>  
            <a href="https://www.occam.ai/">Occam AI</a>

        </p>

        
<br>
                        <div class="member-img">
                          <img src="assets/img/Occam_Ai_black_logo_2 _transparent.png"
                            class="img-fluid" alt>
                        </div>



<br><br>
        <p>  
            <a href="https://www.orby.ai/">Orby AI</a>

        </p>

        
<br>
                        <div class="member-img">
                          <img src="assets/img/Orby AI-2.jpg"
                            class="img-fluid" alt>
                        </div>




      </div> 






                 

              </main><!-- End #main -->

              <!-- ======= Footer ======= -->
              <footer id="footer">
                <div class="container">
                  <div class="copyright">
                    &copy; Copyright <strong><strong>Selecao</strong></strong>.
                    All Rights Reserved
                  </div>
                  <div class="credits">
                    <!-- All the links in the footer should remain intact. -->
                    <!-- You can delete the links only if you purchased the pro version. -->
                    <!-- Licensing information: https://bootstrapmade.com/license/ -->
                    <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/selecao-bootstrap-template/ -->
                    Designed by <a
                      href="https://bootstrapmade.com/">BootstrapMade</a>
                    and <a
                      href="https://doc2dial.github.io/workshop2022/">DialDoc</a>
                  </div>
                </div>
              </footer><!-- End Footer -->

              <a href="#"
                class="back-to-top d-flex align-items-center justify-content-center"><i
                  class="bi bi-arrow-up-short"></i></a>

              <!-- Vendor JS Files -->
              <script src="assets/vendor/aos/aos.js"></script>
              <script
                src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
              <script
                src="assets/vendor/glightbox/js/glightbox.min.js"></script>
              <script
                src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
              <script src="assets/vendor/php-email-form/validate.js"></script>
              <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

              <!-- Template Main JS File -->
              <script src="assets/js/main.js"></script>

              <!-- Default Statcounter code for llmagents.github.io
https://llmagents.github.io/ -->
              <script type="text/javascript">
var sc_project=12953394; 
var sc_invisible=1; 
var sc_security="86f01d45"; 
</script>
              <script type="text/javascript"
                src="https://www.statcounter.com/counter/counter.js"
                async></script>
              <noscript><div class="statcounter"><a title="Web Analytics"
                    href="https://statcounter.com/" target="_blank"><img
                      class="statcounter"
                      src="https://c.statcounter.com/12953394/0/86f01d45/1/"
                      alt="Web Analytics"
                      referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
              <!-- End of Statcounter Code -->

            </body>

          </html>
